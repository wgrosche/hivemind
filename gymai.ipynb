{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/friedrichwilkegrosche/miniforge3/envs/hivemind/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/friedrichwilkegrosche/hivemind/gymai.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000020?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000020?line=7'>8</a>\u001b[0m     observation, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(env\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39msample())\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000020?line=8'>9</a>\u001b[0m     env\u001b[39m.\u001b[39;49mrender()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000020?line=10'>11</a>\u001b[0m     \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000020?line=11'>12</a>\u001b[0m         observation, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset(return_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/hivemind/lib/python3.10/site-packages/gym/core.py:343\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    342\u001b[0m     \u001b[39m\"\"\"Renders the environment with kwargs.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/hivemind/lib/python3.10/site-packages/gym/wrappers/order_enforcing.py:51\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_disable_render_order_enforcing \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[1;32m     47\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\n\u001b[1;32m     48\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot call `env.render()` before calling `env.reset()`, if this is a intended action, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m     )\n\u001b[0;32m---> 51\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/hivemind/lib/python3.10/site-packages/gym/wrappers/env_checker.py:57\u001b[0m, in \u001b[0;36mPassiveEnvChecker.render\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m passive_env_render_check(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     56\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/hivemind/lib/python3.10/site-packages/gym/envs/box2d/lunar_lander.py:672\u001b[0m, in \u001b[0;36mLunarLander.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    670\u001b[0m     pygame\u001b[39m.\u001b[39mevent\u001b[39m.\u001b[39mpump()\n\u001b[1;32m    671\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclock\u001b[39m.\u001b[39mtick(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata[\u001b[39m\"\u001b[39m\u001b[39mrender_fps\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 672\u001b[0m     pygame\u001b[39m.\u001b[39;49mdisplay\u001b[39m.\u001b[39;49mflip()\n\u001b[1;32m    674\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrgb_array\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    675\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mtranspose(\n\u001b[1;32m    676\u001b[0m         np\u001b[39m.\u001b[39marray(pygame\u001b[39m.\u001b[39msurfarray\u001b[39m.\u001b[39mpixels3d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurf)), axes\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    677\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "env.action_space.seed(42)\n",
    "\n",
    "observation, info = env.reset(seed=42, return_info=True)\n",
    "\n",
    "for _ in range(1000):\n",
    "    observation, reward, done, info = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "\n",
    "    if done:\n",
    "        observation, info = env.reset(return_info=True)\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameNotFound",
     "evalue": "Environment SpaceInvaders doesn't exist. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameNotFound\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/friedrichwilkegrosche/hivemind/gymai.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000019?line=0'>1</a>\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39;49mmake(\u001b[39m'\u001b[39;49m\u001b[39mSpaceInvaders-v0\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39munwrapped\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000019?line=2'>3</a>\u001b[0m \u001b[39m# set up matplotlib\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000019?line=3'>4</a>\u001b[0m is_ipython \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m matplotlib\u001b[39m.\u001b[39mget_backend()\n",
      "File \u001b[0;32m~/miniforge3/envs/hivemind/lib/python3.10/site-packages/gym/envs/registration.py:578\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m         logger\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    573\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsing the latest versioned environment `\u001b[39m\u001b[39m{\u001b[39;00mnew_env_id\u001b[39m}\u001b[39;00m\u001b[39m` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minstead of the unversioned environment `\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mid\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         )\n\u001b[1;32m    577\u001b[0m     \u001b[39mif\u001b[39;00m spec_ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 578\u001b[0m         _check_version_exists(ns, name, version)\n\u001b[1;32m    579\u001b[0m         \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo registered env with id: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mid\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    581\u001b[0m _kwargs \u001b[39m=\u001b[39m spec_\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/miniforge3/envs/hivemind/lib/python3.10/site-packages/gym/envs/registration.py:209\u001b[0m, in \u001b[0;36m_check_version_exists\u001b[0;34m(ns, name, version)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mif\u001b[39;00m get_env_id(ns, name, version) \u001b[39min\u001b[39;00m registry:\n\u001b[1;32m    207\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m _check_name_exists(ns, name)\n\u001b[1;32m    210\u001b[0m \u001b[39mif\u001b[39;00m version \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/hivemind/lib/python3.10/site-packages/gym/envs/registration.py:187\u001b[0m, in \u001b[0;36m_check_name_exists\u001b[0;34m(ns, name)\u001b[0m\n\u001b[1;32m    184\u001b[0m namespace_msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m in namespace \u001b[39m\u001b[39m{\u001b[39;00mns\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m ns \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m suggestion_msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDid you mean: `\u001b[39m\u001b[39m{\u001b[39;00msuggestion[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m`?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m suggestion \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 187\u001b[0m \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mNameNotFound(\n\u001b[1;32m    188\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEnvironment \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt exist\u001b[39m\u001b[39m{\u001b[39;00mnamespace_msg\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m{\u001b[39;00msuggestion_msg\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m )\n",
      "\u001b[0;31mNameNotFound\u001b[0m: Environment SpaceInvaders doesn't exist. "
     ]
    }
   ],
   "source": [
    "env = gym.make('SpaceInvaders-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/friedrichwilkegrosche/miniforge3/envs/hivemind/lib/python3.10/site-packages/gym/envs/registration.py:564: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/friedrichwilkegrosche/miniforge3/envs/hivemind/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size=5, stride=2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.6)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                            batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                       if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(\n",
    "        non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values,\n",
    "                     expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/friedrichwilkegrosche/hivemind/gymai.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000016?line=25'>26</a>\u001b[0m state \u001b[39m=\u001b[39m next_state\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000016?line=27'>28</a>\u001b[0m \u001b[39m# Perform one step of the optimization (on the policy network)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000016?line=28'>29</a>\u001b[0m optimize_model()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000016?line=29'>30</a>\u001b[0m \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000016?line=30'>31</a>\u001b[0m     episode_durations\u001b[39m.\u001b[39mappend(t \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m/Users/friedrichwilkegrosche/hivemind/gymai.ipynb Cell 8'\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000015?line=17'>18</a>\u001b[0m reward_batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(batch\u001b[39m.\u001b[39mreward)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000015?line=19'>20</a>\u001b[0m \u001b[39m# Compute Q(s_t, a) - the model computes Q(s_t), then we select the\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000015?line=20'>21</a>\u001b[0m \u001b[39m# columns of actions taken. These are the actions which would've been taken\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000015?line=21'>22</a>\u001b[0m \u001b[39m# for each batch state according to policy_net\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000015?line=22'>23</a>\u001b[0m state_action_values \u001b[39m=\u001b[39m policy_net(state_batch)\u001b[39m.\u001b[39mgather(\u001b[39m1\u001b[39m, action_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000015?line=24'>25</a>\u001b[0m \u001b[39m# Compute V(s_{t+1}) for all next states.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000015?line=25'>26</a>\u001b[0m \u001b[39m# Expected values of actions for non_final_next_states are computed based\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000015?line=26'>27</a>\u001b[0m \u001b[39m# on the \"older\" target_net; selecting their best reward with max(1)[0].\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000015?line=27'>28</a>\u001b[0m \u001b[39m# This is merged based on the mask, such that we'll have either the expected\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000015?line=28'>29</a>\u001b[0m \u001b[39m# state value or 0 in case the state was final.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000015?line=29'>30</a>\u001b[0m next_state_values \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(BATCH_SIZE, device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniforge3/envs/hivemind/lib/python3.10/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/friedrichwilkegrosche/hivemind/gymai.ipynb Cell 5'\u001b[0m in \u001b[0;36mDQN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000012?line=22'>23</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000012?line=23'>24</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000012?line=24'>25</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000012?line=25'>26</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/friedrichwilkegrosche/hivemind/gymai.ipynb#ch0000012?line=26'>27</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn3(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x)))\n",
      "File \u001b[0;32m~/miniforge3/envs/hivemind/lib/python3.10/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/hivemind/lib/python3.10/site-packages/torch/nn/modules/conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 446\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniforge3/envs/hivemind/lib/python3.10/site-packages/torch/nn/modules/conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    440\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    441\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 442\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    443\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "num_episodes = 50\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('hivemind')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68c606508e586a01c3c8026c75f96ff0177306a24be15fc02ae4ce9a5ad27c71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
